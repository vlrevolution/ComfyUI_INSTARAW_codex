class StatsMatcher:
    """
    Computes differentiable losses that encourage an image to match the
    spectral/chroma/texture statistics of real iPhone photos.
    """

    def __init__(self, stats_path: Path, device: torch.device, weights=None):
        data = np.load(stats_path)
        self.device = torch.device(device)
        self.weights = weights or {
            "spectrum": 1.0,
            "chroma": 0.5,
            "texture": 0.25,
        }

        self.spectrum_mean = torch.tensor(
            data["spectra"].mean(axis=0), dtype=torch.float32, device=self.device
        )
        self.chroma_mean = torch.tensor(
            data["chroma_mean"].mean(axis=0), dtype=torch.float32, device=self.device
        )
        self.chroma_cov = torch.tensor(
            data["chroma_cov"].mean(axis=0), dtype=torch.float32, device=self.device
        )
        self.texture_mean = torch.tensor(
            data["glcm"].mean(axis=0), dtype=torch.float32, device=self.device
        )

        self.radial_cache: Dict[Tuple[int, int, int], Dict[str, torch.Tensor]] = {}
        sobel = torch.tensor(
            [[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32, device=self.device
        )
        self.sobel_x = sobel.view(1, 1, 3, 3)
        self.sobel_y = sobel.t().view(1, 1, 3, 3)

    def _radial_profile(self, mag: torch.Tensor, bins: int = 256) -> torch.Tensor:
        b, h, w = mag.shape
        key = (h, w, bins)
        cache = self.radial_cache.get(key)
        if cache is None or cache["index"].device != mag.device:
            y = torch.arange(h, device=mag.device, dtype=torch.float32)
            x = torch.arange(w, device=mag.device, dtype=torch.float32)
            yy, xx = torch.meshgrid(y, x, indexing="ij")
            cy = (h - 1) / 2.0
            cx = (w - 1) / 2.0
            r = torch.sqrt((xx - cx) ** 2 + (yy - cy) ** 2)
            r = torch.clamp(r.long(), max=bins - 1)
            counts = torch.bincount(r.view(-1), minlength=bins).float()
            self.radial_cache[key] = {
                "index": r.view(-1),
                "counts": counts.clamp_min(1.0),
            }
            cache = self.radial_cache[key]
        profile = []
        for sample in mag:
            binsums = torch.zeros(bins, device=mag.device)
            binsums.scatter_add_(0, cache["index"], sample.view(-1))
            profile.append(binsums / cache["counts"])
        return torch.stack(profile, dim=0)

    def __call__(self, img_tensor: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Returns tuple(total_loss, detail_dict).
        """
        b, c, h, w = img_tensor.shape
        stats_losses = {}

        gray = (
            0.299 * img_tensor[:, 0:1]
            + 0.587 * img_tensor[:, 1:2]
            + 0.114 * img_tensor[:, 2:3]
        )
        fft = torch.fft.fftshift(torch.fft.fft2(gray, norm=None), dim=(-1, -2))
        mag = torch.log1p(torch.abs(fft)).mean(1)
        spectrum = self._radial_profile(mag, bins=self.spectrum_mean.shape[0])
        spec_target = self.spectrum_mean.unsqueeze(0)
        stats_losses["spectrum"] = F.mse_loss(spectrum, spec_target)

        pixels = img_tensor.view(b, c, -1)
        mean = pixels.mean(dim=-1, keepdim=True)
        chroma_mean = mean.squeeze(-1)
        stats_losses["chroma_mean"] = F.mse_loss(chroma_mean, self.chroma_mean)
        centered = pixels - mean
        cov = centered @ centered.transpose(1, 2) / pixels.shape[-1]
        stats_losses["chroma_cov"] = F.mse_loss(cov, self.chroma_cov)

        grad_x = F.conv2d(gray, self.sobel_x, padding=1)
        grad_y = F.conv2d(gray, self.sobel_y, padding=1)
        grad_mag = torch.sqrt(grad_x ** 2 + grad_y ** 2 + 1e-8)
        contrast = (grad_mag ** 2).mean(dim=(1, 2, 3))
        mu = F.avg_pool2d(gray, kernel_size=5, stride=1, padding=2)
        var = F.avg_pool2d(gray ** 2, 5, 1, 2) - mu ** 2
        homogeneity = (1.0 / (1.0 + var)).mean(dim=(1, 2, 3))
        texture_vec = torch.stack([contrast.mean(), homogeneity.mean()])
        stats_losses["texture"] = F.mse_loss(texture_vec, self.texture_mean)

        total = (
            self.weights["spectrum"] * stats_losses["spectrum"]
            + self.weights["chroma"] * stats_losses["chroma_mean"]
            + self.weights["chroma"] * stats_losses["chroma_cov"]
            + self.weights["texture"] * stats_losses["texture"]
        )
        return total, stats_losses
